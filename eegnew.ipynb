{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLF48faHpeBU",
        "outputId": "b3efcd9f-730d-4cb1-8ec2-bdf21349c76a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
            "Downloading mne-1.8.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.8.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting latexify-py\n",
            "  Downloading latexify_py-0.4.3.post1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting skfeature-chappers\n",
            "  Downloading skfeature_chappers-1.1.0-py3-none-any.whl.metadata (926 bytes)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting dill>=0.3.2 (from latexify-py)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from skfeature-chappers) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from skfeature-chappers) (2.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->skfeature-chappers) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->skfeature-chappers) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skfeature-chappers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->skfeature-chappers) (3.5.0)\n",
            "Downloading latexify_py-0.4.3.post1-py3-none-any.whl (38 kB)\n",
            "Downloading skfeature_chappers-1.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill, latexify-py, skfeature-chappers\n",
            "Successfully installed dill-0.3.9 latexify-py-0.4.3.post1 skfeature-chappers-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "# Install required Python libraries for EEG processing and machine learning\n",
        "!pip install numpy scipy matplotlib latexify-py skfeature-chappers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUbZoxCqcosh",
        "outputId": "4bb08839-5a72-45fe-b4d8-0b73152db2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDGssEyanoPK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\", message=\".*annotation.*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC-djc6drvYY",
        "outputId": "9a44691b-db76-4ae6-8bd1-869fe5be2833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found files: ['Subject4-[2012.04.08-16.06.48].gdf', 'Subject3-[2012.04.07-18.27.18].gdf', 'Subject2-[2012.04.07-19.44.23].gdf', 'Subject3-[2012.04.07-18.45.34].gdf', 'Subject3-[2012.04.07-18.17.50].gdf', 'Subject2-[2012.04.07-19.36.29].gdf', 'Subject2-[2012.04.07-19.57.52].gdf', 'Subject3-[2012.04.07-18.53.10].gdf', 'Subject2-[2012.04.07-19.27.02].gdf', 'Subject4-[2012.04.08-16.27.27].gdf', 'Subject5-[2012.04.09-19.38.11].gdf', 'Subject5-[2012.04.09-19.48.56].gdf', 'Subject5-[2012.04.09-20.02.48].gdf', 'Subject5-[2012.04.09-19.56.38].gdf', 'Subject4-[2012.04.08-16.19.25].gdf', 'Subject4-[2012.04.08-16.35.27].gdf']\n",
            "Full paths: ['/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject4-[2012.04.08-16.06.48].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject3-[2012.04.07-18.27.18].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject2-[2012.04.07-19.44.23].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject3-[2012.04.07-18.45.34].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject3-[2012.04.07-18.17.50].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject2-[2012.04.07-19.36.29].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject2-[2012.04.07-19.57.52].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject3-[2012.04.07-18.53.10].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject2-[2012.04.07-19.27.02].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject4-[2012.04.08-16.27.27].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject5-[2012.04.09-19.38.11].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject5-[2012.04.09-19.48.56].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject5-[2012.04.09-20.02.48].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject5-[2012.04.09-19.56.38].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject4-[2012.04.08-16.19.25].gdf', '/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject4-[2012.04.08-16.35.27].gdf']\n"
          ]
        }
      ],
      "source": [
        "folder_path = \"/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data\"\n",
        "\n",
        "def data_path(folder_path, data_format=\"gdf\"):\n",
        "    path_files = []  # Store paths of matching files\n",
        "    files = []  # Store file names\n",
        "    folders = []  # Store folder names\n",
        "\n",
        "    # Walk through the directory and collect relevant files/folders\n",
        "    for root, dirnames, filenames in os.walk(folder_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(f\".{data_format}\"):\n",
        "                full_path = os.path.join(root, filename)\n",
        "                path_files.append(full_path)\n",
        "                files.append(filename)\n",
        "        folders.extend(dirnames)\n",
        "\n",
        "    return path_files, files, folders\n",
        "\n",
        "# Get the paths of all GDF files\n",
        "path_files, files, folders = data_path(folder_path, data_format=\"gdf\")\n",
        "\n",
        "# Print the collected file paths\n",
        "print(\"Found files:\", files)\n",
        "print(\"Full paths:\", path_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld7wRtp1tgL5",
        "outputId": "1d50e4e0-ecf7-493b-c3e0-66af3342dfab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GDF file: /content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Data/Subject4-[2012.04.08-16.06.48].gdf\n",
            "Data: (127200, 8) \n",
            "\n",
            "Channels Name: ['Oz', 'O1', 'O2', 'PO3', 'POz', 'PO7', 'PO8', 'PO4'] \n",
            "\n",
            "Labels: ['32769' '33024' '32779' '32780' '33026' '32779' '32780' '33027' '32779'\n",
            " '32780' '33025' '32779' '32780' '33026' '32779' '32780' '33025' '32779'\n",
            " '32780' '33024' '32779' '32780' '33027' '32779' '32780' '33025' '32779'\n",
            " '32780' '33026' '32779' '32780' '33027' '32779' '32780' '33024' '32779'\n",
            " '32780' '33026' '32779' '32780' '33024' '32779' '32780' '33027' '32779'\n",
            " '32780' '33025' '32779' '32780' '33024' '32779' '32780' '33027' '32779'\n",
            " '32780' '33025' '32779' '32780' '33026' '32779' '32780' '33027' '32779'\n",
            " '32780' '33024' '32779' '32780' '33025' '32779' '32780' '33026' '32779'\n",
            " '32780' '33025' '32779' '32780' '33027' '32779' '32780' '33026' '32779'\n",
            " '32780' '33024' '32779' '32780' '33027' '32779' '32780' '33026' '32779'\n",
            " '32780' '33024' '32779' '32780' '33025' '32779' '32780' '33024' '32779'\n",
            " '32780' '33026' '32779' '32780' '33027' '32779' '32780' '33025' '32779'\n",
            " '32780' '33024' '32779' '32780' '33026' '32779' '32780' '33027' '32779'\n",
            " '32780' '33025' '32779' '32780' '32770'] \n",
            "\n",
            "Events: [[ 44752      0      1]\n",
            " [ 45264      0      5]\n",
            " [ 45520      0      3]\n",
            " [ 46800      0      4]\n",
            " [ 47312      0      7]\n",
            " [ 47568      0      3]\n",
            " [ 48848      0      4]\n",
            " [ 49360      0      8]\n",
            " [ 49616      0      3]\n",
            " [ 50896      0      4]\n",
            " [ 51408      0      6]\n",
            " [ 51664      0      3]\n",
            " [ 52944      0      4]\n",
            " [ 53456      0      7]\n",
            " [ 53712      0      3]\n",
            " [ 54992      0      4]\n",
            " [ 55504      0      6]\n",
            " [ 55760      0      3]\n",
            " [ 57040      0      4]\n",
            " [ 57552      0      5]\n",
            " [ 57808      0      3]\n",
            " [ 59088      0      4]\n",
            " [ 59600      0      8]\n",
            " [ 59856      0      3]\n",
            " [ 61136      0      4]\n",
            " [ 61648      0      6]\n",
            " [ 61904      0      3]\n",
            " [ 63184      0      4]\n",
            " [ 63696      0      7]\n",
            " [ 63952      0      3]\n",
            " [ 65232      0      4]\n",
            " [ 65744      0      8]\n",
            " [ 66000      0      3]\n",
            " [ 67280      0      4]\n",
            " [ 67792      0      5]\n",
            " [ 68048      0      3]\n",
            " [ 69328      0      4]\n",
            " [ 69840      0      7]\n",
            " [ 70096      0      3]\n",
            " [ 71376      0      4]\n",
            " [ 71888      0      5]\n",
            " [ 72144      0      3]\n",
            " [ 73424      0      4]\n",
            " [ 73936      0      8]\n",
            " [ 74192      0      3]\n",
            " [ 75472      0      4]\n",
            " [ 75984      0      6]\n",
            " [ 76240      0      3]\n",
            " [ 77520      0      4]\n",
            " [ 78032      0      5]\n",
            " [ 78288      0      3]\n",
            " [ 79568      0      4]\n",
            " [ 80080      0      8]\n",
            " [ 80336      0      3]\n",
            " [ 81616      0      4]\n",
            " [ 82128      0      6]\n",
            " [ 82384      0      3]\n",
            " [ 83664      0      4]\n",
            " [ 84176      0      7]\n",
            " [ 84432      0      3]\n",
            " [ 85712      0      4]\n",
            " [ 86224      0      8]\n",
            " [ 86480      0      3]\n",
            " [ 87760      0      4]\n",
            " [ 88272      0      5]\n",
            " [ 88528      0      3]\n",
            " [ 89808      0      4]\n",
            " [ 90320      0      6]\n",
            " [ 90576      0      3]\n",
            " [ 91856      0      4]\n",
            " [ 92368      0      7]\n",
            " [ 92624      0      3]\n",
            " [ 93904      0      4]\n",
            " [ 94416      0      6]\n",
            " [ 94672      0      3]\n",
            " [ 95952      0      4]\n",
            " [ 96464      0      8]\n",
            " [ 96720      0      3]\n",
            " [ 98000      0      4]\n",
            " [ 98512      0      7]\n",
            " [ 98768      0      3]\n",
            " [100048      0      4]\n",
            " [100560      0      5]\n",
            " [100816      0      3]\n",
            " [102096      0      4]\n",
            " [102608      0      8]\n",
            " [102864      0      3]\n",
            " [104144      0      4]\n",
            " [104656      0      7]\n",
            " [104912      0      3]\n",
            " [106192      0      4]\n",
            " [106704      0      5]\n",
            " [106960      0      3]\n",
            " [108240      0      4]\n",
            " [108752      0      6]\n",
            " [109008      0      3]\n",
            " [110288      0      4]\n",
            " [110800      0      5]\n",
            " [111056      0      3]\n",
            " [112336      0      4]\n",
            " [112848      0      7]\n",
            " [113104      0      3]\n",
            " [114384      0      4]\n",
            " [114896      0      8]\n",
            " [115152      0      3]\n",
            " [116432      0      4]\n",
            " [116944      0      6]\n",
            " [117200      0      3]\n",
            " [118480      0      4]\n",
            " [118992      0      5]\n",
            " [119248      0      3]\n",
            " [120528      0      4]\n",
            " [121040      0      7]\n",
            " [121296      0      3]\n",
            " [122576      0      4]\n",
            " [123088      0      8]\n",
            " [123344      0      3]\n",
            " [124624      0      4]\n",
            " [125136      0      6]\n",
            " [125392      0      3]\n",
            " [126672      0      4]\n",
            " [127184      0      2]] \n",
            "\n",
            "Event Indices: {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5, '33025': 6, '33026': 7, '33027': 8} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ensure the path_files variable contains GDF file paths\n",
        "print(f\"Using GDF file: {path_files[0]}\")\n",
        "\n",
        "# Read the GDF file into a raw MNE object\n",
        "raw = mne.io.read_raw_gdf(path_files[0], verbose=0)\n",
        "\n",
        "# Extract the channel names from the raw data\n",
        "channels_name = raw.ch_names\n",
        "\n",
        "# Get the EEG data and transpose it to have channels as rows and samples as columns\n",
        "data = 1e6 * raw.get_data().T  # Convert to microvolts if necessary\n",
        "\n",
        "# Get the sampling frequency of the EEG data\n",
        "fs = raw.info['sfreq']\n",
        "\n",
        "# Extract labels from annotations\n",
        "labels = raw.annotations.description\n",
        "\n",
        "# Get the events and their corresponding indices\n",
        "events, event_ind = mne.events_from_annotations(raw, verbose=0)\n",
        "\n",
        "# Print all the relevant information\n",
        "print(f\"Data: {data.shape} \\n\")\n",
        "print(f\"Channels Name: {channels_name} \\n\")\n",
        "print(f\"Labels: {labels} \\n\")\n",
        "print(f\"Events: {events} \\n\")\n",
        "print(f\"Event Indices: {event_ind} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a DataFrame for the EEG data with channel names as columns\n",
        "df = pd.DataFrame(data, columns=channels_name)\n",
        "# Add the labels to the DataFrame as a new column\n",
        "df['Labels'] = labels\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "GG5k_ZaG6qQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpEf3ezRFFDB"
      },
      "source": [
        "Filtering/ feature Extraction / Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmB7YnMGCI2l",
        "outputId": "5718bf52-9b73-43e2-c557-5e5565e08d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape : (1280, 8, 160)\n",
            "Filtered data shape: (1280, 8, 160)\n"
          ]
        }
      ],
      "source": [
        "#Import required libraries\n",
        "import numpy as np\n",
        "import mne\n",
        "import warnings\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/Code/Python/Functions')\n",
        "\n",
        "# Import functions from the .py files in the Functions folder\n",
        "from Filtering import filtering\n",
        "\n",
        "# Step 4: Define your parameters for filtering\n",
        "trial = 8            # Define trial number (trial 1 in Python index starts from 0)\n",
        "order = 3            # Define filter order\n",
        "f_low = 0.05         # Define lower cutoff frequency for the bandpass filter (Hz)\n",
        "f_high = 100         # Define upper cutoff frequency for the bandpass filter (Hz)\n",
        "notch_freq = 50      # Define frequency to be removed from the signal for notch filter (Hz)\n",
        "quality_factor = 20  # Define quality factor for the notch filter\n",
        "notch_filter = \"on\"  # on or off\n",
        "filter_active = \"on\" # on or off\n",
        "design_method = \"IIR\" # IIR or FIR\n",
        "type_filter = \"bandpass\"  # low, high, bandpass, or bandstop\n",
        "freq_stim = 13       # Define stimulation frequency\n",
        "\n",
        "\n",
        "# Step 5: Apply bandpass filtering to the EEG data\n",
        "filtered_data = filtering(data1, f_low, f_high, order, fs, notch_freq, quality_factor,\n",
        "                          filter_active, notch_filter, type_filter, design_method)\n",
        "\n",
        "# Print the shape of the filtered data to verify\n",
        "print(f\"Filtered data shape: {filtered_data.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7M3aFA-Wq3R"
      },
      "source": [
        "CAR Filter (Common average reference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH9pTa0ZCIpq",
        "outputId": "d309d154-2df4-43dc-ade6-57286b5d8004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CAR-filtered data shape: (1280, 8, 160)\n",
            "CAR-filtered data for Trial 1: (1280, 8)\n"
          ]
        }
      ],
      "source": [
        "#Import the CAR filter function\n",
        "from Common_average_reference import car\n",
        "\n",
        "# Step 3: Apply CAR filter to the data\n",
        "# filtered_data shape: (1280, 8, 160)\n",
        "data_car = car(filtered_data, reference_channel=None)  # Use all channels for average reference\n",
        "\n",
        "# Step 4: Verify the shape of CAR-filtered data\n",
        "print(f\"CAR-filtered data shape: {data_car.shape}\")\n",
        "\n",
        "# Step 5: Extract the trial-specific data if needed\n",
        "trial = 0  # Define trial number (0-indexed)\n",
        "trial_data_car = data_car[:, :, trial]  # Extract data for the selected trial\n",
        "\n",
        "# Step 6: Verify the trial data shape\n",
        "print(f\"CAR-filtered data for Trial {trial + 1}: {trial_data_car.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mesmd1Vc3HhI"
      },
      "source": [
        "CCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQGdpBjm4ezb",
        "outputId": "78afb92d-50a9-4d14-b67a-c9165547e30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Data Shape: (1280, 8, 480)\n",
            "CAR-Filtered Data Shape: (1280, 8, 480)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 1. 2. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 0. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 2. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1.\n",
            " 2. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
            " 1. 0. 1. 0. 0. 1. 1. 1. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            "Classification Accuracy: 92.08%\n"
          ]
        }
      ],
      "source": [
        "# Import functions\n",
        "from Filtering import filtering\n",
        "from Common_average_reference import car\n",
        "from CCA import cca\n",
        "\n",
        "# ------------------------------------ Step 2: Load and Combine Data ----------------------------------------\n",
        "# Assuming data1, data2, and data3 are already loaded\n",
        "data_total = np.concatenate((data1, data2, data3), axis=2)\n",
        "\n",
        "# Generate labels for each dataset (0, 1, 2)\n",
        "labels = np.concatenate((np.full(data1.shape[-1], 0),\n",
        "                         np.full(data2.shape[-1], 1),\n",
        "                         np.full(data3.shape[-1], 2)))\n",
        "\n",
        "# ------------------------------------ Step 3: Filter the Data ----------------------------------------\n",
        "order = 4\n",
        "f_low = 0.05\n",
        "f_high = 100\n",
        "notch_freq = 50\n",
        "quality_factor = 20\n",
        "notch_filter = \"on\"\n",
        "filter_active = \"off\"\n",
        "type_filter = \"bandpass\"\n",
        "\n",
        "filtered_data = filtering(data_total, f_low, f_high, order, fs,\n",
        "                          notch_freq, quality_factor, filter_active,\n",
        "                          notch_filter, type_filter)\n",
        "\n",
        "print(f\"Filtered Data Shape: {filtered_data.shape}\")\n",
        "\n",
        "# ----------------------------------- Step 4: Apply CAR Filter ----------------------------------------\n",
        "data_car = car(filtered_data)\n",
        "print(f\"CAR-Filtered Data Shape: {data_car.shape}\")\n",
        "\n",
        "# ----------------------------------- Step 5: Perform CCA Classification ----------------------------------------\n",
        "num_channel = [0, 1, 2]   # List of channels to use\n",
        "num_harmonic = 4          # Number of harmonics\n",
        "f_stim = [13, 21, 17]     # Frequencies used for stimulation\n",
        "\n",
        "# Use your CCA function to classify the EEG signals\n",
        "predict_label = cca(data_car, fs, f_stim, num_channel, num_harmonic)\n",
        "\n",
        "print(predict_label)\n",
        "\n",
        "# ------------------------------------ Step 6: Calculate Accuracy ----------------------------------------\n",
        "accuracy = np.sum(labels == predict_label) / len(predict_label) * 100\n",
        "print(f\"Classification Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkFhtNHJ-kmb"
      },
      "source": [
        "Feature Extraction using CCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARyIJ-lY1n_z",
        "outputId": "09d2057a-982b-4e61-804d-71959ab6c44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Features:  [[8.48613455e-02 1.54841890e-03 1.33326683e-04 ... 1.58246850e-03\n",
            "  1.06533270e-03 5.81540495e-05]\n",
            " [6.66169000e-02 5.70067345e-03 8.63946117e-05 ... 2.63545705e-03\n",
            "  2.29649073e-04 1.03755950e-04]\n",
            " [1.42600851e-02 1.74431970e-04 2.57166498e-05 ... 3.34775379e-04\n",
            "  7.92737126e-05 3.45241246e-05]\n",
            " ...\n",
            " [8.77509493e-03 2.36960440e-03 8.25896660e-05 ... 4.97390480e-02\n",
            "  6.14588787e-03 1.69494663e-04]\n",
            " [1.64460169e-03 1.78155409e-04 2.32833164e-05 ... 1.63746702e-02\n",
            "  1.01678326e-02 1.23096439e-04]\n",
            " [3.45830215e-03 1.76787469e-03 5.19363368e-04 ... 4.43240847e-02\n",
            "  8.52655063e-03 5.35432503e-04]]\n",
            "Extracted Features Shape:  [[8.48613455e-02 1.54841890e-03 1.33326683e-04 ... 1.58246850e-03\n",
            "  1.06533270e-03 5.81540495e-05]\n",
            " [6.66169000e-02 5.70067345e-03 8.63946117e-05 ... 2.63545705e-03\n",
            "  2.29649073e-04 1.03755950e-04]\n",
            " [1.42600851e-02 1.74431970e-04 2.57166498e-05 ... 3.34775379e-04\n",
            "  7.92737126e-05 3.45241246e-05]\n",
            " ...\n",
            " [8.77509493e-03 2.36960440e-03 8.25896660e-05 ... 4.97390480e-02\n",
            "  6.14588787e-03 1.69494663e-04]\n",
            " [1.64460169e-03 1.78155409e-04 2.32833164e-05 ... 1.63746702e-02\n",
            "  1.01678326e-02 1.23096439e-04]\n",
            " [3.45830215e-03 1.76787469e-03 5.19363368e-04 ... 4.43240847e-02\n",
            "  8.52655063e-03 5.35432503e-04]]\n"
          ]
        }
      ],
      "source": [
        "#Import functions from the files\n",
        "import Filtering\n",
        "import Common_average_reference\n",
        "import CCA_Feature_Extraction\n",
        "import numpy as np\n",
        "\n",
        "#Combine all datasets\n",
        "data_total = np.concatenate((data1, data2, data3), axis=2)\n",
        "labels = np.concatenate((np.full(data1.shape[-1], 0),\n",
        "                         np.full(data2.shape[-1], 1),\n",
        "                         np.full(data3.shape[-1], 2)))\n",
        "\n",
        "# Define filtering parameters\n",
        "order = 3                # Define filter order\n",
        "notch_freq = 50          # Define frequency to be removed from the signal for notch filter (Hz)\n",
        "quality_factor = 20      # Define quality factor for the notch filter\n",
        "subbands = [[12, 16, 20], [14, 18, 22]]\n",
        "f_low = np.min(subbands) - 1  # Define lower cutoff frequency for the bandpass filter (Hz)\n",
        "f_high = np.max(subbands) + 1  # Define upper cutoff frequency for the bandpass filter (Hz)\n",
        "notch_filter = \"on\"       # on or off\n",
        "filter_active = \"on\"      # on or off\n",
        "type_filter = \"bandpass\"  # low, high, bandpass, or bandstop\n",
        "\n",
        "# Apply notch filter to the EEG data\n",
        "filtered_data = Filtering.filtering(data_total, f_low, f_high, order, fs,\n",
        "                                     notch_freq, quality_factor,\n",
        "                                     filter_active, notch_filter, type_filter)\n",
        "\n",
        "# Perform Common Average Reference (CAR)\n",
        "data_car = Common_average_reference.car(filtered_data)\n",
        "\n",
        "# Define parameters for feature extraction\n",
        "num_channel = [0, 1, 2]   # List of channels to use\n",
        "num_harmonic = 2          # Number of harmonics\n",
        "f_stim = [13, 21, 17]     # Frequencies stimulation\n",
        "\n",
        "title = f\"Feature Extraction using CCA\"\n",
        "\n",
        "# Perform CCA feature extraction\n",
        "features_extraction = CCA_Feature_Extraction.cca_feature_extraction(data_car, fs, f_stim, num_channel, num_harmonic)\n",
        "\n",
        "# Print or visualize the extracted features\n",
        "print(\"Extracted Features: \", features_extraction)\n",
        "print(\"Extracted Features Shape: \", features_extraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SZE1aAV_8D6"
      },
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpejSg62_74i",
        "outputId": "87fc504f-9c6a-48e0-cc48-ad307986a438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features shape: (480, 4)\n"
          ]
        }
      ],
      "source": [
        "# Import the feature selection function from the uploaded file\n",
        "from Feature_selections import feature_selecions\n",
        "\n",
        "# Define parameters for feature selection\n",
        "num_features = 4\n",
        "n_neighbors_MI = 5                 # Number of neighbors to consider for mutual information calculation.\n",
        "L1_Parameter = 0.1                 # Parameter value for L1 regularization.\n",
        "threshold_var = 0.001              # The threshold used for variance thresholding.\n",
        "type_feature_selection = \"anova\"    # Options: var, anova, mi, ufs, rfe, rf, l1fs, tfs, fs, ffs, bfs\n",
        "title = f\"Feature selection using {type_feature_selection}\"\n",
        "\n",
        "# Perform feature selection\n",
        "features = feature_selecions(features_extraction, labels, num_features, threshold_var,\n",
        "                              n_neighbors_MI, L1_Parameter, type_feature_selection)\n",
        "\n",
        "# Display the selected features\n",
        "print(f\"Selected features shape: {features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uczhDeR7CXl8"
      },
      "source": [
        "Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming `features_extraction` and `labels` are already available from the previous steps\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features_extraction, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "# Step 3: Standardize the features (important for models like SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate models on the test set\n",
        "models = {#\"Logistic Regression\": logreg,\n",
        "           \"SVM\": svm_model\n",
        "          #  , \"Random Forest\": rf_model\n",
        "          }\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 6: Define action mapping based on predictions\n",
        "def action_mapping(prediction):\n",
        "    actions = {\n",
        "        0: \"13\",\n",
        "        1: \"21\",\n",
        "        2: \"17\"\n",
        "    }\n",
        "    return actions.get(prediction, \"Unknown Action\")\n",
        "\n",
        "print(f\"Xtest = {X_test.shape}\")\n",
        "print(f\"Xtrain = {X_train.shape}\")\n",
        "\n",
        "\n",
        "# Step 7: Test the model with some example data\n",
        "for i in range (features.shape[1]):\n",
        "    sample = X_test[i].reshape(1, -1)  # Example data point\n",
        "    predicted_label = rf_model.predict(sample)[0]\n",
        "    predicted_action = action_mapping(predicted_label)\n",
        "\n",
        "    print(f\"Predicted Action: {predicted_action}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzGMqGtYm-nE",
        "outputId": "4636fa2d-99a9-4cd1-f6ce-5b42aac5f198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SVM ---\n",
            "Accuracy: 1.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        34\n",
            "           1       1.00      1.00      1.00        27\n",
            "           2       1.00      1.00      1.00        35\n",
            "\n",
            "    accuracy                           1.00        96\n",
            "   macro avg       1.00      1.00      1.00        96\n",
            "weighted avg       1.00      1.00      1.00        96\n",
            "\n",
            "Xtest = (96, 9)\n",
            "Xtrain = (384, 9)\n",
            "Predicted Action: 13\n",
            "Predicted Action: 17\n",
            "Predicted Action: 17\n",
            "Predicted Action: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8FTYhMhcaqc"
      },
      "source": [
        "## DEPLOYMENT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the .npy file\n",
        "data1 = np.load('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/trials/13hz.npy') [:,:,0]\n",
        "data2 = np.load('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/trials/21hz.npy')[:,:,0]\n",
        "data3 = np.load('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/trials/17hz.npy')[:,:,0]\n",
        "\n",
        "# Example event information (you should have these from the old data)\n",
        "event_ind = {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5,\n",
        "             '33025': 6, '33026': 7, '33027': 8}\n",
        "\n",
        "# Original labels (from the old data)\n",
        "labels_old = ['32769', '33024', '32779', '32780', '33026', '32779', '32780', '33027',\n",
        "              '32779', '32780', '33025', '32779', '32780', '33026', '32779', '32780', '33025']\n",
        "\n",
        "# For this example, I assume you're extracting labels based on row indices (adjust based on actual event times)\n",
        "# This should match the number of rows in your new datasets (1280 rows)\n",
        "labels_new = []\n",
        "for i in range(data1.shape[0]):\n",
        "    event_idx = i % len(labels_old)  # Adjust this if the labels are not sequential\n",
        "    labels_new.append(labels_old[event_idx])\n",
        "\n",
        "# Convert list to a NumPy array\n",
        "labels_new = np.array(labels_new)\n",
        "\n",
        "# Now, we have the new data and corresponding labels (1280 rows x 8 columns, labels array with 1280 items)\n",
        "# Data Channels Names\n",
        "channels_name = ['Oz', 'O1', 'O2', 'PO3', 'POz', 'PO7', 'PO8', 'PO4']  # Example for 8 channels\n",
        "\n",
        "# Convert data to microvolts (if necessary, depending on your data's scale)\n",
        "data = 1e6 * data1  # Assuming data1, data2, data3 are the subsets\n",
        "\n",
        "# Sampling frequency (adjust based on your data)\n",
        "fs = 256  # Example, adjust as per your dataset's fs\n",
        "\n",
        "# Placeholder for events (adjust according to your dataset's event times and values)\n",
        "events = np.array([[44752, 0, 1], [45264, 0, 5], [45520, 0, 3]])  # Example events\n",
        "event_ind = {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5,\n",
        "             '33025': 6, '33026': 7, '33027': 8}  # Event mapping\n",
        "\n",
        "# Print all the relevant information for the new data and labels\n",
        "print(f\"Data: {data.shape} \\n\")\n",
        "print(f\"Channels Name: {channels_name} \\n\")\n",
        "print(f\"Labels: {labels_new} \\n\")\n",
        "print(f\"Events: {events} \\n\")\n",
        "print(f\"Event Indices: {event_ind} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep3d3ZGlpj75",
        "outputId": "18d7ff84-95e9-4f3c-d6d1-5b34455e2361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: (1280, 8) \n",
            "\n",
            "Channels Name: ['Oz', 'O1', 'O2', 'PO3', 'POz', 'PO7', 'PO8', 'PO4'] \n",
            "\n",
            "Labels: ['32769' '33024' '32779' ... '32779' '32780' '33026'] \n",
            "\n",
            "Events: [[44752     0     1]\n",
            " [45264     0     5]\n",
            " [45520     0     3]] \n",
            "\n",
            "Event Indices: {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5, '33025': 6, '33026': 7, '33027': 8} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a DataFrame for the EEG data\n",
        "df = pd.DataFrame(data, columns=channels_name)\n",
        "# Add the labels to the DataFrame\n",
        "df['Labels'] = labels_new\n",
        "# Display the first few rows to visualize the table\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA1iTy756W1Z",
        "outputId": "07a37f42-4ae0-4364-e662-b05fbbabae29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Oz            O1            O2           PO3           POz  \\\n",
            "0  23235.375434   3562.177861    -59.469420 -19892.062483  14099.685808   \n",
            "1   -472.635590 -12376.284620 -12042.557594 -35832.756058  -9404.871507   \n",
            "2  -7867.095619 -17384.645801 -17543.478965 -40520.311568 -15822.133913   \n",
            "3   9833.869524  -5099.699075  -6705.177130 -23482.850197   3978.397834   \n",
            "4  34502.398036  14659.731967   8177.045280  -4462.192264  25699.535430   \n",
            "\n",
            "            PO7           PO8           PO4 Labels  \n",
            "0   8298.748630  16671.916336  22422.587836  32769  \n",
            "1 -11857.491285  -3945.489097  12022.388204  33024  \n",
            "2 -15625.571744 -10575.690700   5685.240324  32779  \n",
            "3    388.770206   6274.217624  19739.154404  32780  \n",
            "4  23012.205660  26535.639079  32944.072595  33026  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the .npy file data (assuming data is in shape [num_trials, num_samples, num_channels])\n",
        "data1 = np.load('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/trials/13hz.npy')[:,:,0]  # 13 Hz trial data\n",
        "data2 = np.load('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/trials/21hz.npy')[:,:,0]  # 21 Hz trial data\n",
        "data3 = np.load('/content/drive/MyDrive/SSVEP-based-EEG-signal-processing-main/SSVEP-based-EEG-signal-processing-main/trials/17hz.npy')[:,:,0]  # 17 Hz trial data\n",
        "\n",
        "# Example event information (adjust to match your real event timings and indices)\n",
        "event_ind = {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5,\n",
        "             '33025': 6, '33026': 7, '33027': 8}  # Define event labels (these map to specific event types)\n",
        "\n",
        "# Original labels from old dataset (for reference, these will be assigned based on trials)\n",
        "labels_old = ['32769', '33024', '32779', '32780', '33026', '32779', '32780', '33027',\n",
        "              '32779', '32780', '33025', '32779', '32780', '33026', '32779', '32780', '33025']\n",
        "\n",
        "# For this example, we map labels based on the total number of trials (adjust if events follow a different pattern)\n",
        "labels_new = []\n",
        "\n",
        "# Example: if we have 1280 trials per data set (change according to the real size of your data)\n",
        "# Assign labels cyclically from the old labels for each subset of data (data1, data2, data3)\n",
        "num_trials = data1.shape[0]  # Assuming data1 has 1280 trials\n",
        "for i in range(num_trials):\n",
        "    event_idx = i % len(labels_old)  # This will wrap around and assign labels cyclically\n",
        "    labels_new.append(labels_old[event_idx])\n",
        "\n",
        "# Convert list to NumPy array\n",
        "labels_new = np.array(labels_new)\n",
        "\n",
        "# Assuming data1, data2, data3 are 1280 trials x 8 channels (adjust based on your data)\n",
        "# Collect all data into one array (e.g., for combined trials) for consistency\n",
        "all_data = np.concatenate([data1, data2, data3], axis=0)  # Stack data vertically (along rows)\n",
        "\n",
        "# Channels Names (example for 8 channels)\n",
        "channels_name = ['Oz', 'O1', 'O2', 'PO3', 'POz', 'PO7', 'PO8', 'PO4']\n",
        "\n",
        "# Define the sampling frequency (adjust as per your dataset's actual fs)\n",
        "fs = 256  # Example, adjust based on your data's sample frequency\n",
        "\n",
        "# Placeholder for event timings (replace with actual event times and values)\n",
        "events = np.array([[44752, 0, 1], [45264, 0, 5], [45520, 0, 3]])  # Example event array\n",
        "event_ind = {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5,\n",
        "             '33025': 6, '33026': 7, '33027': 8}  # Map event indices\n",
        "\n",
        "# Now, let's print the relevant information\n",
        "print(f\"Data Shape: {all_data_microvolts.shape} (trials x channels) \\n\")\n",
        "print(f\"Channels Names: {channels_name} \\n\")\n",
        "print(f\"Labels (for {num_trials * 3} trials): {labels_new} \\n\")\n",
        "print(f\"Events (example): {events} \\n\")\n",
        "print(f\"Event Indices: {event_ind} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAASQH-7v6gX",
        "outputId": "5d62d3d5-e5b3-49f1-d306-5cd27b14d464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (3840, 8) (trials x channels) \n",
            "\n",
            "Channels Names: ['Oz', 'O1', 'O2', 'PO3', 'POz', 'PO7', 'PO8', 'PO4'] \n",
            "\n",
            "Labels (for 3840 trials): ['32769' '33024' '32779' ... '32779' '32780' '33026'] \n",
            "\n",
            "Events (example): [[44752     0     1]\n",
            " [45264     0     5]\n",
            " [45520     0     3]] \n",
            "\n",
            "Event Indices: {'32769': 1, '32770': 2, '32779': 3, '32780': 4, '33024': 5, '33025': 6, '33026': 7, '33027': 8} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Convert data1 into a DataFrame\n",
        "df = pd.DataFrame(data1)\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBfp1r0Uq_S5",
        "outputId": "646fac31-65fb-4a1d-995c-e3fc4eb55dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             0         1         2         3         4         5         6  \\\n",
            "0     0.023235  0.003562 -0.000059 -0.019892  0.014100  0.008299  0.016672   \n",
            "1    -0.000473 -0.012376 -0.012043 -0.035833 -0.009405 -0.011857 -0.003945   \n",
            "2    -0.007867 -0.017385 -0.017543 -0.040520 -0.015822 -0.015626 -0.010576   \n",
            "3     0.009834 -0.005100 -0.006705 -0.023483  0.003978  0.000389  0.006274   \n",
            "4     0.034502  0.014660  0.008177 -0.004462  0.025700  0.023012  0.026536   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1275  0.030538  0.016974 -0.000877 -0.018435  0.019496  0.014594  0.021700   \n",
            "1276  0.008767  0.002162 -0.012176 -0.032272 -0.001021 -0.003125 -0.001379   \n",
            "1277 -0.008751 -0.008540 -0.018911 -0.039619 -0.016264 -0.013054 -0.010442   \n",
            "1278 -0.003049 -0.007870 -0.017945 -0.037846 -0.010472 -0.008777 -0.005058   \n",
            "1279  0.020384  0.010702 -0.006497 -0.022702  0.013932  0.010901  0.016865   \n",
            "\n",
            "             7  \n",
            "0     0.022423  \n",
            "1     0.012022  \n",
            "2     0.005685  \n",
            "3     0.019739  \n",
            "4     0.032944  \n",
            "...        ...  \n",
            "1275  0.022847  \n",
            "1276  0.006913  \n",
            "1277  0.001865  \n",
            "1278  0.005549  \n",
            "1279  0.016343  \n",
            "\n",
            "[1280 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data1.shape)\n",
        "print(data2.shape)\n",
        "print(data3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBCF_GlnqCKf",
        "outputId": "9360d2bd-64e1-417f-de2b-f260eeee8b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8,)\n",
            "(1280, 8)\n",
            "(1280, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import scipy.signal as signal\n",
        "\n",
        "\n",
        "# Generate the labels for each dataset (e.g., data1 = 13Hz, data2 = 21Hz, data3 = 17Hz)\n",
        "y1 = np.full(data1.shape[0], 13)  # Label all data1 as 13Hz\n",
        "y2 = np.full(data2.shape[0], 21)  # Label all data2 as 21Hz\n",
        "y3 = np.full(data3.shape[0], 17)  # Label all data3 as 17Hz\n",
        "\n",
        "# Combining data and labels\n",
        "X = np.vstack([data1, data2, data3])\n",
        "y = np.concatenate([y1, y2, y3])  #labels/frequencies\n",
        "\n",
        "#Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Initialize and train a Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "#accuracy = accuracy_score(y_test, y_pred)\n",
        "# predicted labels back tofrequency\n",
        "label_to_freq = {\n",
        "    '13': 13,\n",
        "    '17': 17,\n",
        "    '21': 21\n",
        "}\n",
        "\n",
        "# Mapping labels to frequencies\n",
        "predicted_frequencies = [label_to_freq[str(label)] for label in y_pred]\n",
        "\n",
        "# Output the predicted frequencies for each trial\n",
        "print(\"\\nPredicted Frequencies for Each Trial:\")\n",
        "for i, freq in enumerate(predicted_frequencies[:20]):  # first 20 predictions\n",
        "    print(f\"Trial {i + 1}: {freq} Hz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhHkPRAfxrav",
        "outputId": "d13b4c05-cb25-49d1-8fee-990655c69155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Frequencies for Each Trial:\n",
            "Trial 1: 13 Hz\n",
            "Trial 2: 17 Hz\n",
            "Trial 3: 13 Hz\n",
            "Trial 4: 17 Hz\n",
            "Trial 5: 21 Hz\n",
            "Trial 6: 17 Hz\n",
            "Trial 7: 17 Hz\n",
            "Trial 8: 21 Hz\n",
            "Trial 9: 17 Hz\n",
            "Trial 10: 13 Hz\n",
            "Trial 11: 21 Hz\n",
            "Trial 12: 17 Hz\n",
            "Trial 13: 21 Hz\n",
            "Trial 14: 21 Hz\n",
            "Trial 15: 17 Hz\n",
            "Trial 16: 13 Hz\n",
            "Trial 17: 17 Hz\n",
            "Trial 18: 21 Hz\n",
            "Trial 19: 17 Hz\n",
            "Trial 20: 17 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qisbxQL-7dJ5"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}